{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/envs/bigdata/lib/python3.8/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/20 22:47:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "/opt/conda/envs/bigdata/lib/python3.8/site-packages/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf()\n",
    "\n",
    "conf.set('spark.ui.proxyBase', '/user/' + os.environ['JUPYTERHUB_USER'] + '/proxy/4041')\n",
    "conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
    "conf.set('spark.driver.memory','4g')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "\n",
    "spark = pyspark.SQLContext.getOrCreate(sc)\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import regexp_replace, trim, col, lower,date_format,split,explode,desc,hour\n",
    "from pyspark.sql.types import StructType,StructField, StringType,DoubleType\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "bakery = spark.read.option(\"inferSchema\",True).option(\"header\",True).csv(\"Bakery.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>Items</th><th>date</th><th>hour</th><th>count</th></tr>\n",
       "<tr><td>Coke</td><td>2016-01-11</td><td>13</td><td>1</td></tr>\n",
       "<tr><td>Medialuna</td><td>2016-01-11</td><td>16</td><td>1</td></tr>\n",
       "<tr><td>Cookies</td><td>2016-01-11</td><td>15</td><td>1</td></tr>\n",
       "<tr><td>Bread</td><td>2016-01-11</td><td>15</td><td>1</td></tr>\n",
       "<tr><td>Jam</td><td>2016-01-11</td><td>14</td><td>1</td></tr>\n",
       "<tr><td>Tea</td><td>2016-01-11</td><td>15</td><td>2</td></tr>\n",
       "<tr><td>Eggs</td><td>2016-01-11</td><td>16</td><td>1</td></tr>\n",
       "<tr><td>Tea</td><td>2016-01-11</td><td>8</td><td>3</td></tr>\n",
       "<tr><td>Victorian Sponge</td><td>2016-01-11</td><td>9</td><td>1</td></tr>\n",
       "<tr><td>Tea</td><td>2016-01-11</td><td>11</td><td>1</td></tr>\n",
       "<tr><td>Cookies</td><td>2016-01-11</td><td>12</td><td>2</td></tr>\n",
       "<tr><td>Bread</td><td>2016-01-11</td><td>16</td><td>1</td></tr>\n",
       "<tr><td>Fudge</td><td>2016-01-11</td><td>14</td><td>1</td></tr>\n",
       "<tr><td>Medialuna</td><td>2016-01-11</td><td>18</td><td>1</td></tr>\n",
       "<tr><td>Coffee</td><td>2016-01-11</td><td>14</td><td>4</td></tr>\n",
       "<tr><td>Bread</td><td>2016-01-11</td><td>13</td><td>1</td></tr>\n",
       "<tr><td>Alfajores</td><td>2016-01-11</td><td>15</td><td>1</td></tr>\n",
       "<tr><td>Scandinavian</td><td>2016-01-11</td><td>14</td><td>2</td></tr>\n",
       "<tr><td>Soup</td><td>2016-01-11</td><td>15</td><td>1</td></tr>\n",
       "<tr><td>Coffee</td><td>2016-01-11</td><td>15</td><td>2</td></tr>\n",
       "</table>\n",
       "only showing top 20 rows\n"
      ],
      "text/plain": [
       "+----------------+----------+----+-----+\n",
       "|           Items|      date|hour|count|\n",
       "+----------------+----------+----+-----+\n",
       "|            Coke|2016-01-11|  13|    1|\n",
       "|       Medialuna|2016-01-11|  16|    1|\n",
       "|         Cookies|2016-01-11|  15|    1|\n",
       "|           Bread|2016-01-11|  15|    1|\n",
       "|             Jam|2016-01-11|  14|    1|\n",
       "|             Tea|2016-01-11|  15|    2|\n",
       "|            Eggs|2016-01-11|  16|    1|\n",
       "|             Tea|2016-01-11|   8|    3|\n",
       "|Victorian Sponge|2016-01-11|   9|    1|\n",
       "|             Tea|2016-01-11|  11|    1|\n",
       "|         Cookies|2016-01-11|  12|    2|\n",
       "|           Bread|2016-01-11|  16|    1|\n",
       "|           Fudge|2016-01-11|  14|    1|\n",
       "|       Medialuna|2016-01-11|  18|    1|\n",
       "|          Coffee|2016-01-11|  14|    4|\n",
       "|           Bread|2016-01-11|  13|    1|\n",
       "|       Alfajores|2016-01-11|  15|    1|\n",
       "|    Scandinavian|2016-01-11|  14|    2|\n",
       "|            Soup|2016-01-11|  15|    1|\n",
       "|          Coffee|2016-01-11|  15|    2|\n",
       "+----------------+----------+----+-----+\n",
       "only showing top 20 rows"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bakery = bakery.withColumn(\"time\", date_format('DateTime', 'HH:mm:ss'))\n",
    "bakery = bakery.withColumn(\"date\", date_format('DateTime', 'yyyy-MM-dd'))\n",
    "bakery = bakery.withColumn(\"hour\", hour(F.to_timestamp(\"time\",\"HH:mm:ss\")))\n",
    "bakery.groupBy(\"Items\",\"date\",\"hour\").count().orderBy(\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery2 = bakery.groupBy(\"Items\",\"DayType\", \"Daypart\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [\"Items\",\"DayType\",\"Daypart\"]\n",
    "window = Window.partitionBy(bakery2['DayType'],bakery2['Daypart']).orderBy(bakery2['count'].desc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bakery2 = bakery2.select('*', rank().over(window).alias('rank')).filter(col('rank') <= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------------------------------------------+\n",
      "|DayType|Daypart  |collect_list(Items)                       |\n",
      "+-------+---------+------------------------------------------+\n",
      "|Weekday|Afternoon|[Coffee, Bread, Tea]                      |\n",
      "|Weekday|Evening  |[Coffee, Bread, Tea]                      |\n",
      "|Weekday|Morning  |[Coffee, Bread, Pastry]                   |\n",
      "|Weekday|Night    |[Valentine's card, Juice, Mineral water]  |\n",
      "|Weekend|Afternoon|[Coffee, Bread, Tea]                      |\n",
      "|Weekend|Evening  |[Tshirt, Coffee, Afternoon with the baker]|\n",
      "|Weekend|Morning  |[Coffee, Bread, Pastry]                   |\n",
      "|Weekend|Night    |[Vegan Feast, Hot chocolate, Scandinavian]|\n",
      "+-------+---------+------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bakery2 =bakery2.groupBy(\"DayType\",\"Daypart\").agg(F.collect_list(\"Items\"))\n",
    "bakery2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = spark.read.option(\"inferSchema\",True).option(\"header\",True).option(\"delimiter\",\";\").csv(\"Restaurants_in_Durham_County_NC.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|       Rpt_Area_Desc|count|\n",
      "+--------------------+-----+\n",
      "|  Bed&Breakfast Home|    4|\n",
      "|        Summer Camps|    4|\n",
      "|        Institutions|   30|\n",
      "|   Local Confinement|    2|\n",
      "|         Mobile Food|  147|\n",
      "|    School Buildings|   89|\n",
      "|                null|   13|\n",
      "|         Summer Food|  242|\n",
      "|      Swimming Pools|  420|\n",
      "|            Day Care|  173|\n",
      "|Tattoo Establishm...|   32|\n",
      "|    Residential Care|  154|\n",
      "|   Bed&Breakfast Inn|    2|\n",
      "|      Adult Day Care|    5|\n",
      "|             Lodging|   62|\n",
      "|        Food Service| 1093|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "restaurants.groupBy(\"Rpt_Area_Desc\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = spark.read.option(\"inferSchema\",True).option(\"header\",True).csv(\"populationbycountry19802010millions.csv\")\n",
    "population = population.withColumnRenamed(\"_c0\",\"Country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "population1 = population.select(\n",
    "    'Country',\n",
    "    *[F.round((((F.col(str(year)) - F.col(str(int(year)-1))) / F.col(str(int(year)-1)))*100),3).alias(year)\n",
    "      for year in population.columns[2:]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/20 22:50:42 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: \n",
      " Schema: _c0\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n"
     ]
    }
   ],
   "source": [
    "pivot_df = population1.groupby(population1.columns[1:]) \\\n",
    "                        .pivot('Country') \\\n",
    "                        .max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "  StructField('year', StringType(), True),\n",
    "  StructField('Country', StringType(), True),\n",
    "  StructField('Max increase', StringType(), True)\n",
    "  ])\n",
    "df = spark.createDataFrame([],schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/20 22:51:01 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1980, 1981\n",
      " Schema: _c0, 1980, 1981\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1980, 1981\n",
      " Schema: _c0, 1980, 1981\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1981, 1982\n",
      " Schema: _c0, 1981, 1982\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:02 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1981, 1982\n",
      " Schema: _c0, 1981, 1982\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1982, 1983\n",
      " Schema: _c0, 1982, 1983\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1982, 1983\n",
      " Schema: _c0, 1982, 1983\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:03 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1983, 1984\n",
      " Schema: _c0, 1983, 1984\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1983, 1984\n",
      " Schema: _c0, 1983, 1984\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1984, 1985\n",
      " Schema: _c0, 1984, 1985\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1984, 1985\n",
      " Schema: _c0, 1984, 1985\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:04 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1985, 1986\n",
      " Schema: _c0, 1985, 1986\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1985, 1986\n",
      " Schema: _c0, 1985, 1986\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1986, 1987\n",
      " Schema: _c0, 1986, 1987\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:05 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1986, 1987\n",
      " Schema: _c0, 1986, 1987\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1987, 1988\n",
      " Schema: _c0, 1987, 1988\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1987, 1988\n",
      " Schema: _c0, 1987, 1988\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1988, 1989\n",
      " Schema: _c0, 1988, 1989\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:06 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1988, 1989\n",
      " Schema: _c0, 1988, 1989\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1989, 1990\n",
      " Schema: _c0, 1989, 1990\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1989, 1990\n",
      " Schema: _c0, 1989, 1990\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1990, 1991\n",
      " Schema: _c0, 1990, 1991\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1990, 1991\n",
      " Schema: _c0, 1990, 1991\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1991, 1992\n",
      " Schema: _c0, 1991, 1992\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:08 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1991, 1992\n",
      " Schema: _c0, 1991, 1992\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1992, 1993\n",
      " Schema: _c0, 1992, 1993\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1992, 1993\n",
      " Schema: _c0, 1992, 1993\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1993, 1994\n",
      " Schema: _c0, 1993, 1994\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1993, 1994\n",
      " Schema: _c0, 1993, 1994\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:09 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1994, 1995\n",
      " Schema: _c0, 1994, 1995\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1994, 1995\n",
      " Schema: _c0, 1994, 1995\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1995, 1996\n",
      " Schema: _c0, 1995, 1996\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1995, 1996\n",
      " Schema: _c0, 1995, 1996\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1996, 1997\n",
      " Schema: _c0, 1996, 1997\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:10 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1996, 1997\n",
      " Schema: _c0, 1996, 1997\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1997, 1998\n",
      " Schema: _c0, 1997, 1998\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1997, 1998\n",
      " Schema: _c0, 1997, 1998\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1998, 1999\n",
      " Schema: _c0, 1998, 1999\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:11 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1998, 1999\n",
      " Schema: _c0, 1998, 1999\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1999, 2000\n",
      " Schema: _c0, 1999, 2000\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 1999, 2000\n",
      " Schema: _c0, 1999, 2000\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2000, 2001\n",
      " Schema: _c0, 2000, 2001\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:12 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2000, 2001\n",
      " Schema: _c0, 2000, 2001\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2001, 2002\n",
      " Schema: _c0, 2001, 2002\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2001, 2002\n",
      " Schema: _c0, 2001, 2002\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2002, 2003\n",
      " Schema: _c0, 2002, 2003\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2002, 2003\n",
      " Schema: _c0, 2002, 2003\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2003, 2004\n",
      " Schema: _c0, 2003, 2004\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:13 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2003, 2004\n",
      " Schema: _c0, 2003, 2004\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2004, 2005\n",
      " Schema: _c0, 2004, 2005\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2004, 2005\n",
      " Schema: _c0, 2004, 2005\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2005, 2006\n",
      " Schema: _c0, 2005, 2006\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2005, 2006\n",
      " Schema: _c0, 2005, 2006\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2006, 2007\n",
      " Schema: _c0, 2006, 2007\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:14 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2006, 2007\n",
      " Schema: _c0, 2006, 2007\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2007, 2008\n",
      " Schema: _c0, 2007, 2008\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2007, 2008\n",
      " Schema: _c0, 2007, 2008\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2008, 2009\n",
      " Schema: _c0, 2008, 2009\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:15 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2008, 2009\n",
      " Schema: _c0, 2008, 2009\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:16 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2009, 2010\n",
      " Schema: _c0, 2009, 2010\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n",
      "22/03/20 22:51:16 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , 2009, 2010\n",
      " Schema: _c0, 2009, 2010\n",
      "Expected: _c0 but found: \n",
      "CSV file: file:///home/jovyan/populationbycountry19802010millions.csv\n"
     ]
    }
   ],
   "source": [
    "for year in population1.columns[1:]:\n",
    "    df1 = population1.select(\"Country\",year).orderBy(col(year).desc()).limit(1)\n",
    "    df1\n",
    "    df_row = spark.createDataFrame([(year,df1.collect()[0][0],df1.collect()[0][1])], schema)\n",
    "    df = df.union(df_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------------+------------+\n",
      "|year|             Country|Max increase|\n",
      "+----+--------------------+------------+\n",
      "|1981|      Western Sahara|      12.133|\n",
      "|1982|      Western Sahara|      11.115|\n",
      "|1983|       French Guiana|      14.286|\n",
      "|1984|               Qatar|      10.964|\n",
      "|1985|       French Guiana|        12.5|\n",
      "|1986|               Qatar|       8.772|\n",
      "|1987|       French Guiana|      11.111|\n",
      "|1988|      Cayman Islands|       11.01|\n",
      "|1989|United Arab Emirates|        6.12|\n",
      "|1990|            Djibouti|      12.824|\n",
      "|1991|              Jordan|      11.274|\n",
      "|1992|              Kuwait|      48.633|\n",
      "|1993|         Afghanistan|      13.225|\n",
      "|1994|         Afghanistan|       8.728|\n",
      "|1995|             Burundi|       7.222|\n",
      "|1996|              Rwanda|      19.614|\n",
      "|1997|Falkland Islands ...|        21.5|\n",
      "|1998|             Liberia|      12.017|\n",
      "|1999|Falkland Islands ...|       7.692|\n",
      "|2000|          Montserrat|      16.864|\n",
      "+----+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphanumeric(column):\n",
    "    return trim(lower(regexp_replace(column, '([^0-9a-zA-Z])+', ' '))).alias('sentence')\n",
    "file_path = 'internet_archive_scifi_v3.txt'\n",
    "text_file = spark.read.option(\"lineSep\", \".\").text(file_path).select(alphanumeric(col('value')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file1 = (text_file\n",
    "                    .select(split(text_file.sentence, '\\s+').alias('split')))\n",
    "text_file2 = (text_file1\n",
    "                    .select(explode(text_file1.split).alias('word')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  word|count|\n",
      "+------+-----+\n",
      "|      |91509|\n",
      "|     0|   10|\n",
      "|    00|   52|\n",
      "|   000|   40|\n",
      "| 000th|    1|\n",
      "|    03|    1|\n",
      "|    05|    1|\n",
      "|   060|    1|\n",
      "|    07|    1|\n",
      "|     1|  150|\n",
      "|    10|   29|\n",
      "|   100|    5|\n",
      "|  1000|    4|\n",
      "|1000th|    1|\n",
      "|   101|    5|\n",
      "|   102|    5|\n",
      "|   103|    4|\n",
      "|   104|    5|\n",
      "|   105|    6|\n",
      "|   106|    3|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def wordCount(file):\n",
    "     return (file\n",
    "                .groupBy('word').count())\n",
    "word_count = wordCount(text_file2)\n",
    "topwords = word_count.orderBy(\"word\")\n",
    "\n",
    "topwords.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def alphanumeric(text):\n",
    "    text = re.sub(\"[^0-9a-zA-Z ]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "rdd = sc.textFile(\"internet_archive_scifi_v3.txt\")\n",
    "row = rdd.flatMap(lambda x : x.split(\". \"))\n",
    "row = row.map(alphanumeric).map(lambda x : x.lower())\n",
    "\n",
    "def bigram(words):\n",
    "    bigrams = []\n",
    "    for i in range(len(words) - 1):\n",
    "        bigrams.append((tuple(words[i:i+2]), 1))\n",
    "    return bigrams\n",
    "\n",
    "bigrams = row.map(lambda s : s.split()).flatMap(bigram)\n",
    "freq_bigrams = bigrams.reduceByKey(lambda x, y: x + y).map(lambda x : (x[1], x[0])).sortByKey(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "topcount = freq_bigrams.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(157766, ('of', 'the')),\n",
       " (101616, ('in', 'the')),\n",
       " (69666, ('to', 'the')),\n",
       " (57452, ('on', 'the')),\n",
       " (56108, ('it', 'was')),\n",
       " (46022, ('and', 'the')),\n",
       " (44147, ('don', 't')),\n",
       " (43626, ('at', 'the')),\n",
       " (39428, ('to', 'be')),\n",
       " (38236, ('he', 'was'))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topcount[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "durham = spark.read.json(\"durham-nc-foreclosure-2006-2016.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "durham = durham.filter(durham.fields.geocode.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants1 = restaurants.filter((restaurants.Status == \"ACTIVE\") & (restaurants.Rpt_Area_Desc == \"Food Service\") & (restaurants.geolocation.isNotNull()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "durham1 = durham.join(restaurants1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import haversine\n",
    "def findDistance(geoClosure,geoRestaurant):\n",
    "    lat1,long1 = geoClosure\n",
    "    lat2,long2 = geoRestaurant.split(\",\")\n",
    "    lat2 = lat2.strip()\n",
    "    long2.strip()\n",
    "    distance = haversine.haversine((float(lat1),float(long1)),(float(lat2),float(long2)))\n",
    "    return distance\n",
    "UDF = udf(findDistance)  \n",
    "durham2 = durham1.withColumn(\"distance\", F.round(UDF(col(\"fields.geocode\"),col(\"geolocation\")),2).cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "durham3 = durham2.where(durham2.distance<=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/20 23:05:36 WARN ExtractPythonUDFFromJoinCondition: The join condition:(round(cast(findDistance(_extract_geocode#43124, geolocation#241) as double), 2) <= 1.0) of the join plan contains PythonUDF only, it will be moved out and the join plan will be turned to cross join.\n",
      "[Stage 105:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|    ID|count|\n",
      "+------+-----+\n",
      "| 58358|    2|\n",
      "|147244|   28|\n",
      "| 57180|   32|\n",
      "| 57655|    3|\n",
      "| 58318|    4|\n",
      "| 56081|   16|\n",
      "|155004|   21|\n",
      "| 99093|  191|\n",
      "|180224|    1|\n",
      "| 57048|   17|\n",
      "| 76848|   14|\n",
      "| 56656|    1|\n",
      "| 56926|    1|\n",
      "|148160|    1|\n",
      "| 56685|   23|\n",
      "| 80693|   12|\n",
      "| 56171|   17|\n",
      "| 57164|    3|\n",
      "|170723|    6|\n",
      "| 56849|   26|\n",
      "+------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "durham3.groupBy(\"ID\").count().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'Python Interactive'",
   "language": "python",
   "name": "85ece1c8-d54a-4c63-9dfd-a64d22c92a1f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
